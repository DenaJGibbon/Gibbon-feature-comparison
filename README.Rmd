---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Overview
This is the repository for: 'Mel-frequency cepstral coefficients outperform embeddings from pre-trained convolutional neural networks under noisy conditions for discrimination tasks of individual gibbons' (Lakdari et al, under review). The goal of the paper is to compare different approaches of feature extraction for individual discrimination of gibbon female calls. Acoustic data can be downloaded at: 10.5281/zenodo.8205685.

Feature extraction was done in both R and Python, and analyses for publication were done in R.

# Feature/embedding extraction

### MFCCs
MFCCs are calculated using the 'Processing features for randomization' R script. 

### BirdNET
Follow the installation instructions here: https://github.com/kahst/BirdNET-Analyzer. Then use the 'BirdNET Terminal Script'. 

### VGGish
Follow installation instructions: https://github.com/tensorflow/models/blob/master/research/audioset/vggish/README.md. Then use the 'VGGish Terminal Script'.

### Wav2Vec2
Wav2Vec2 embeddings are caluclated using the 'Wav2Vec2_Features.py' Python script.

### Acoustic indices
Acoustic indices are calculated using the 'Processing features for randomization' R script. 

# SNR calculation

# Supervised classification and unsupervised clustering


